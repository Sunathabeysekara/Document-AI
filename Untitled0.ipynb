{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7w4uQDitEWnz"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3FUNAd3E29W"
      },
      "source": [
        "installing sdk for python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uJEcIELjEw4v"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfekj1PFDwp"
      },
      "source": [
        "importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "slwzPWUeE_dC"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWu3uGqOFbG-"
      },
      "source": [
        "Setup your API key¶\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "Get an API key\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "Put the key in the GOOGLE_API_KEY environment variable (the SDK will automatically pick it up from there).\n",
        "Pass the key to genai.configure(api_key=...)\n",
        "key=\n",
        "\n",
        "AIzaSyD63BFXnAkSeFTTSVPQ6zYl6dhW3k-SdCk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pDe462WTE_PW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "genai.configure(\n",
        "    # Put the key in the GOOGLE_API_KEY\n",
        "    api_key=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVEdwQMVFuwY"
      },
      "source": [
        "Now you're ready to call the Gemini API. Use list_models to see the available Gemini models:\n",
        "\n",
        "gemini-pro: optimized for text-only prompts.\n",
        "gemini-pro-vision: optimized for text-and-images prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "fj1ric2_FweY",
        "outputId": "6f3f0f63-d8d0-4d69-e6e9-0d1b57b1194c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0827\n"
          ]
        }
      ],
      "source": [
        "for model in genai.list_models():\n",
        "    if 'generateContent' in model.supported_generation_methods:\n",
        "        print(model.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFNgopcXF55z"
      },
      "source": [
        "For text-only prompts, use the gemini-pro model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ppu9Y5pqF6rw"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name='gemini-pro'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9F9OsLwF-1K"
      },
      "source": [
        "The generate_content method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n",
        "In the simplest case, you can pass a prompt string to the GenerativeModel.generate_content method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X_CrabRxGB5f"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\"why should use kaggle?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "naQFfIwXGKVJ",
        "outputId": "11a294b5-a297-445e-cedf-7ab5a79969f4"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> **1. Access to a Vast Dataset Repository:**\n",
              "> Kaggle hosts a wealth of labeled and unlabeled datasets spanning various domains, including healthcare, finance, natural language processing, and more. This allows you to train and evaluate your models on real-world data.\n",
              "> \n",
              "> **2. Real-World Problem-Solving:**\n",
              "> Kaggle competitions pose real-world problems that require innovative solutions. Participating in these challenges allows you to apply your skills to practical problems and showcase your abilities.\n",
              "> \n",
              "> **3. Collaborative Learning Environment:**\n",
              "> Kaggle fosters a collaborative environment where data scientists and machine learning enthusiasts can share knowledge, discuss techniques, and learn from each other. You can connect with experts, get feedback, and contribute to the community.\n",
              "> \n",
              "> **4. Skill Validation and Certification:**\n",
              "> Kaggle offers a range of certifications that validate your data science skills. These certifications can enhance your credibility and demonstrate your proficiency to potential employers.\n",
              "> \n",
              "> **5. Career Opportunities:**\n",
              "> Many companies actively recruit from Kaggle, using it as a platform to identify talented data scientists. Participating in competitions and showcasing your skills can increase your chances of getting noticed by potential employers.\n",
              "> \n",
              "> **6. Continuous Learning:**\n",
              "> Kaggle provides access to a variety of courses, tutorials, and workshops that cover data science fundamentals, advanced techniques, and industry best practices. This allows you to continuously develop your knowledge and skills.\n",
              "> \n",
              "> **7. Networking and Mentorship:**\n",
              "> Kaggle hosts regular events, meetups, and discussion forums that provide opportunities for networking and mentorship. You can connect with like-minded professionals, find mentors, and build valuable relationships.\n",
              "> \n",
              "> **8. Data Visualization and Sharing:**\n",
              "> Kaggle provides interactive visualization tools and notebooks that allow you to explore and share your datasets and models. This facilitates data analysis, hypothesis testing, and knowledge dissemination.\n",
              "> \n",
              "> **9. Benchmarking and Model Comparison:**\n",
              "> Kaggle allows you to compare your models' performance with other participants in competitions. This enables you to benchmark your solutions, identify areas for improvement, and learn from the best practices of others.\n",
              "> \n",
              "> **10. Data Analytics and Insights Generation:**\n",
              "> Kaggle provides a platform for exploring and analyzing datasets to uncover insights, patterns, and trends. This can lead to valuable business decisions and knowledge generation."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
